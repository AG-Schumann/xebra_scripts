{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T10:44:49.018713Z",
     "start_time": "2019-09-23T10:44:43.592779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ab602/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 12:44:48.584542 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0923 12:44:48.593572 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0923 12:44:48.667513 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0923 12:44:48.667975 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0923 12:44:48.668344 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0923 12:44:48.731892 139840347338560 deprecation_wrapper.py:119] From /home/ab602/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Imports:\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "## Load the trained model from corresponding HDF5 file\n",
    "model_NN = keras.models.load_model('XeBRA_Position_Reconstruction_NN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T10:44:49.022426Z",
     "start_time": "2019-09-23T10:44:49.019814Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Position Reconstruction for XeBRA\n",
    "\n",
    "Version 0.0.1: Weighted Sum\n",
    "Version 0.0.2: LRF\n",
    "Version 0.0.3: Neural Network\n",
    "\n",
    "Status: September 2019, Version 0.0.3\n",
    "\n",
    "Position reconstruction for XeBRA using a Deep Feed Forward (DFF) Neural Network \n",
    "with Keras trained on Geant4 MC simulations.\n",
    "'''\n",
    "\n",
    "def reconstructed_position(input_array):\n",
    "    ## Normalize sum input to 1 in order to correspond to area fraction in top array\n",
    "    HFs_input = input_array / np.sum(input_array)\n",
    "    ## Use model to reconstruct position\n",
    "    ## Important: Factor 70 for rescaling label\n",
    "    predictions = model_NN.predict(np.array([HFs_input]))[0]*70\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T10:44:49.053943Z",
     "start_time": "2019-09-23T10:44:49.023819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.397104, 17.57973 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_feature = np.array([0.02448657, 0.04107425, 0.06240126, 0.4399684 , 0.23933649,  0.04107425, 0.15165877])\n",
    "reconstructed_position(predict_feature)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict_feature.shape\n",
    "    (20000, 7)\n",
    "predict_feature[0]\n",
    "    array([0.02448657, 0.04107425, 0.06240126, 0.4399684 , 0.23933649,\n",
    "       0.04107425, 0.15165877])\n",
    "predictions[0]\n",
    "    array([18.397106, 17.579727], dtype=float32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@export\n",
    "@strax.takes_config(\n",
    "    strax.Option('to_pe', track=False, help='PMT gains',\n",
    "                     default_by_run=utils.GetGains),\n",
    "    strax.Option('top_pmts', track=False, default=list(range(1,7+1)),\n",
    "                 type=list, help=\"Which PMTs are in the top array\"),\n",
    "    strax.Option('min_reconstruction_area',\n",
    "                 help='Skip reconstruction if area_top (PE) is less than this',\n",
    "                 default=100)\n",
    ")\n",
    "class PeakPositions(strax.Plugin):\n",
    "    '''\n",
    "    Position Reconstruction for XeBRA\n",
    "\n",
    "    Version 0.0.1: Weighted Sum\n",
    "    Version 0.0.2: LRF\n",
    "    Version 0.0.3: Neural Network\n",
    "\n",
    "    Status: September 2019, Version 0.0.3\n",
    "\n",
    "    Position reconstruction for XeBRA using a Deep Feed Forward (DFF) Neural Network \n",
    "    with Keras trained on Geant4 MC simulations.\n",
    "    '''\n",
    "    __version__ = \"0.0.3\"\n",
    "    dtype = [('x', np.float32,\n",
    "              'Reconstructed S2 X position (mm), uncorrected'),\n",
    "             ('y', np.float32,\n",
    "              'Reconstructed S2 Y position (mm), uncorrected')]\n",
    "    depends_on = ('peaks',)\n",
    "    parallel = True\n",
    "\n",
    "    def setup(self):\n",
    "        ## PMT mask - select top PMTs\n",
    "        self.pmt_mask = np.zeros_like(self.config['to_pe'], dtype=np.bool)\n",
    "        self.pmt_mask[self.config['top_pmts']] = np.ones_like(self.pmt_mask[self.config['top_pmts']])\n",
    "        ## Load the trained model from corresponding HDF5 file\n",
    "        self.model_NN = keras.models.load_model('/data/workspace/nn_models/XeBRA_Position_Reconstruction_NN_Model_DualPhase_7TopPMTs.h5')\n",
    "        \n",
    "    def compute(self, peaks):\n",
    "        ## Keep large peaks only\n",
    "        results = np.full_like(peaks, np.nan, dtype=self.dtype)\n",
    "\n",
    "        for p_i,p in enumerate(peaks):\n",
    "            apc = p['area_per_channel'][self.pmt_mask]\n",
    "            if apc.sum() < self.config['min_reconstruction_area']:\n",
    "                continue\n",
    "            results[p_i] = tuple(self.reconstructed_position(apc))\n",
    "        return results\n",
    "\n",
    "    ## Reconstruct position inside S2 region\n",
    "    def reconstructed_position(self, input_array):\n",
    "        ## Normalize sum input to 1 in order to correspond to area fraction in top array\n",
    "        HFs_input = input_array / np.sum(input_array)\n",
    "        ## Use model to reconstruct position\n",
    "        ## Important: Factor 70 for rescaling label\n",
    "        predictions = self.model_NN.predict(np.array([HFs_input]))[0]*70\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@export\n",
    "@strax.takes_config(\n",
    "    strax.Option('to_pe', track=False, help='PMT gains',\n",
    "                     default_by_run=utils.GetGains),\n",
    "    strax.Option('top_pmts', track=False, default=list(range(1,7+1)),\n",
    "                 type=list, help=\"Which PMTs are in the top array\"),\n",
    "    strax.Option('min_reconstruction_area',\n",
    "                 help='Skip reconstruction if area_top (PE) is less than this',\n",
    "                 default=100)\n",
    ")\n",
    "class PeakPositions(strax.Plugin):\n",
    "    '''\n",
    "    Position Reconstruction for XeBRA\n",
    "    \n",
    "    Version 0.0.1: weighted sum\n",
    "    Version 0.0.2: LRF\n",
    "    \n",
    "    Status: July 2019, Version 0.0.2\n",
    "    \n",
    "    Position reconstruction for XeBRA following the position reconstruction algorithm of Mercury \n",
    "    (employed in the LUX experiment, originally developed for the ZEPLIN-III dark matter experiment) \n",
    "    with light response functions (see https://arxiv.org/abs/1710.02752v2 and \n",
    "    https://arxiv.org/abs/1112.1481 ).\n",
    "    '''\n",
    "    __version__ = \"0.0.2\"\n",
    "    dtype = [('x', np.float32,\n",
    "              'Reconstructed S2 X position (mm), uncorrected'),\n",
    "             ('y', np.float32,\n",
    "              'Reconstructed S2 Y position (mm), uncorrected')]\n",
    "    depends_on = ('peaks',)\n",
    "    parallel = True\n",
    "\n",
    "    def setup(self):\n",
    "        # PMT mask\n",
    "        self.pmt_mask = np.zeros_like(self.config['to_pe'], dtype=np.bool)\n",
    "        self.pmt_mask[self.config['top_pmts']] = self.config['to_pe'][self.config['top_pmts']] > 0\n",
    "        # PMT positions in mm in cartesian coordinates\n",
    "        pmt_x = np.array([-14.,-28.,-14.,14.,28.,14.,0.]) # x-positions PMTs\n",
    "        pmt_x = pmt_x[self.pmt_mask[self.config['top_pmts']]]\n",
    "        pmt_y = np.array([-28.,0.,28.,28.,0.,-28.,0.])    # y-positions PMTs\n",
    "        pmt_y = pmt_y[self.pmt_mask[self.config['top_pmts']]]\n",
    "        self.pmt_positions = np.column_stack((pmt_x, pmt_y))\n",
    "        # Fit parameters LRFs\n",
    "        # MC driven (R_PTFE = 95 %, T_meshes = 89.770509 %, lambda_LXe = 100 cm); \n",
    "        # To be iteratively determined from data later\n",
    "        self.fitparameters = np.array([[ 0.58534179, 29.89341846, -0.3275816, 4.14715081, 2.61234684], \n",
    "                          [ 0.63546614, 28.49525342, -0.19651583, 3.76011493, 2.68672152], \n",
    "                          [ 0.58840586, 30.39015033, -0.38248759, 4.27642323, 2.56774842], \n",
    "                          [ 0.59111988, 31.38350968, -0.5760228, 4.64122418, 2.51311592], \n",
    "                          [ 0.63771524, 28.90663204, -0.26194541, 3.90052756, 2.66510948], \n",
    "                          [ 0.59030322, 30.55082687, -0.46183924, 4.39769959, 2.55446814], \n",
    "                          [ 0.53114467, 39.20861977, -17.93187819, 20.60397171, 2.27692367]])\n",
    "        self.fitparameters = self.fitparameters[self.pmt_mask[self.config['top_pmts']]]\n",
    "        \n",
    "    def compute(self, peaks):\n",
    "        # Keep large peaks only\n",
    "        peak_mask = peaks['area'] > self.config['min_reconstruction_area']\n",
    "        p = peaks['area_per_channel'][peak_mask, :]\n",
    "        p = p[:, self.pmt_mask]\n",
    "        results = np.full_like(peaks, np.nan, dtype=self.dtype)\n",
    "\n",
    "        for p_i,p in enumerate(peaks):\n",
    "            apc = p['area_per_channel'][self.pmt_mask]\n",
    "            if apc.sum() < self.config['min_reconstruction_area']:\n",
    "                continue\n",
    "            results[p_i] = tuple(self.reconstructed_position(apc))\n",
    "        return results\n",
    "\n",
    "    # Function to return non-negative value corresponding to (radial position - radius TPC) if inside TPC,\n",
    "    # used for constraints\n",
    "    @staticmethod\n",
    "    def insidevolume(inputs):\n",
    "        p_TPC_radius = 35\n",
    "        return (p_TPC_radius - np.hypot(inputs[0], inputs[1]))\n",
    "    \n",
    "    # Radial LRF model\n",
    "    # from: Position Reconstruction in a Dual Phase Xenon Scintillation Detector (https://arxiv.org/abs/1112.1481)\n",
    "    @staticmethod\n",
    "    def eta(r, A, r0, a, b, alpha):\n",
    "        return A * np.exp( - a * (r/r0) / (1 + (r/r0) ** (1 - alpha)) - b / (1 + (r/r0) ** (- alpha)))   \n",
    "\n",
    "    ## Position dependent LRF values individual PMTs from model\n",
    "    def LRF_PMTs(self, x, y):\n",
    "        LRF_PMTs_array = np.array([(self.eta(np.sqrt((x - self.pmt_positions[j, 0])**2 + (y - self.pmt_positions[j, 1])**2), *self.fitparameters[j])) for j in range(0,(self.pmt_positions).shape[0])])\n",
    "        return LRF_PMTs_array / (np.sum(LRF_PMTs_array))\n",
    "    \n",
    "    ## Reconstruct position inside S2 region\n",
    "    def reconstructed_position(self, input_array):\n",
    "        HFs_input = input_array / np.sum(input_array)\n",
    "        reconstruct = lambda x: np.sum(((self.LRF_PMTs(x[0], x[1]) - HFs_input)**2) / (self.LRF_PMTs(x[0], x[1])))\n",
    "        x0 = [0.001,0.001]\n",
    "        meth = 'SLSQP'\n",
    "        cons = ({'type': 'ineq', \"fun\": self.insidevolume})\n",
    "        res = minimize(reconstruct, x0, method=meth, constraints=cons)\n",
    "        return res.x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "169px",
    "width": "491.767px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
